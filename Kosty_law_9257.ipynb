{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import random\n",
    "import catboost\n",
    "from catboost import CatBoostRegressor, Pool, CatBoostClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Downloading Data. \n",
    "    \n",
    "    All files and folders are extracted from zip and placed in the same folder as .ipynb \n",
    "    \n",
    "    Creating df which includes text data. No NaNs\n",
    "    \n",
    "    regulations_texts.csv is used for df['text'], 'ria_reports/ria_reports/ria_reports_main.csv'  for  df['co_developer']\n",
    "    \n",
    "    After that, only df is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11384"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"regulations.csv\")\n",
    "df_texts = pd.read_csv(\"regulations_texts.csv\", sep=\";\")\n",
    "answers = pd.read_csv(\"train_answer.csv\")\n",
    "df_reports = pd.read_csv('ria_reports/ria_reports/ria_reports_main.csv', sep=\";\")\n",
    "\n",
    "df['publication_date'] = pd.to_datetime(df['publication_date'])\n",
    "df['text'] = [df_texts[df_texts['regulation_project_id'] == x].iat[0,1] \n",
    "              if x in set(df_texts['regulation_project_id']) else 'nothing' for x in df['id']]\n",
    "df['co_developer'] = [df_reports[df_reports['regulation_project_id'] == x].iat[0,3] \n",
    "              if x in set(df_reports['regulation_project_id']) else 'nothing' for x in df['id']]\n",
    "\n",
    "#Get rid of nans\n",
    "for col in df:\n",
    "    #get dtype for column\n",
    "    dt = df[col].dtype \n",
    "    #check if it is a number\n",
    "    if dt == int or dt == float or dt == 'float64':\n",
    "        df[col] = df[col].fillna(0)\n",
    "    else:\n",
    "        df[col] = df[col].fillna(\"nothing\")\n",
    "\n",
    "len(df_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Preparing Data\n",
    "    \n",
    "    Creating df1_cat_dev which has only numeric data\n",
    "\n",
    "    Actually the main function data_proc(df, answers) was used to return 3 tables: df1, df1_cat, df1_cat_dev. But only the last one was used for the final submissions.\n",
    "    df1 - fully numerical\n",
    "    df1_cat - with some categorical features\n",
    "    df1_cat_dev - with lots of categorical features (including developers)\n",
    "    \n",
    "    df1 and df1_cat were deleted from function for simplicity\n",
    "    That's the reason why df1_cat_dev has such a strange name!\n",
    "    \n",
    "    df1_cat_dev has 24 features and an 'id' column which will be deleted later.\n",
    "    \n",
    "added_by\n",
    "\n",
    "responsible\n",
    "\n",
    "year\n",
    "\n",
    "developer\n",
    "\n",
    "regulatory_impact\n",
    "\n",
    "mineco_solution\n",
    "\n",
    "views_num\n",
    "\n",
    "month\n",
    "\n",
    "npa_type\n",
    "\n",
    "act_objectives\n",
    "\n",
    "year_end\n",
    "\n",
    "text_len\n",
    "\n",
    "co_dev_mean\n",
    "\n",
    "dislikes_num\n",
    "\n",
    "проект\n",
    "\n",
    "act_significance\n",
    "\n",
    "persons_affected_by_act\n",
    "\n",
    "text\n",
    "\n",
    "problem_addressed\n",
    "\n",
    "is_regionally_signigicant\n",
    "\n",
    "okved_list\n",
    "\n",
    "relations_regulated_by_act\n",
    "\n",
    "co_developer_bool\n",
    "\n",
    "act_changes_controlling_activities\n",
    "\n",
    "Features are ordered according to catboost feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def co_dev_columns(X, y):\n",
    "    '''\n",
    "        Dealing with \"co_developers\"\n",
    "        Creating features:\n",
    "            'co_developer_count' - the number of  co_developers\n",
    "            'co_dev_mean' - mean success for co_developers (mean from the means)\n",
    "            'co_developer_bool' - are there any co_devs\n",
    "    '''\n",
    "    \n",
    "    X = X.copy()\n",
    "    X['answer'] = y\n",
    "    \n",
    "    X['co_developer_bool'] = [0 if x.lstrip().lower() in ['nothing', 'нет', 'отсутствуют', '-', 'соисполнителейнет', \n",
    "                                                         'соисполнителей-нет','соисполнителиотсутствуют'] else \n",
    "                            1 for x in df['co_developer']]\n",
    "    \n",
    "    X['co_dev_mean'] = [0 for i in range(len(X))]\n",
    "    X['co_developer_count'] = [0 for i in range(len(X))]\n",
    "    for x in df['developer'].unique():\n",
    "        if x != 'nothing':\n",
    "            X['co_dev_' + x] = [1 if x in t else 0 for t in df['co_developer']]\n",
    "            X['co_developer_count'] = X['co_developer_count'] + X['co_dev_' + x]\n",
    "            if X['co_dev_' + x].sum() != 0:\n",
    "                succ_rate = (X['co_dev_' + x]*X['answer']).sum()/X['co_dev_' + x].sum()\n",
    "                X['co_dev_' + x] = [succ_rate if t != 0 else 0 for t in X['co_dev_' + x]]\n",
    "                X['co_dev_mean'] = X['co_dev_mean'] + X['co_dev_' + x]\n",
    "\n",
    "            del X['co_dev_' + x]\n",
    "\n",
    "    X['co_dev_mean'] = X['co_dev_mean']/X['co_developer_count']\n",
    "    X['co_dev_mean'] = [x if x < 10000 else 0 for x in X['co_dev_mean']]\n",
    "    del X['co_developer_count']\n",
    "    del X['answer']\n",
    "    return X\n",
    "\n",
    "\n",
    "def data_proc(df, answers):\n",
    "    '''\n",
    "        Creating the table df1_cat_dev for catboost\n",
    "    '''\n",
    "    df1 = df.loc[:,['id', 'publication_date', 'act_title', 'developer', 'okved_list', 'views_num', \n",
    "                    'dislikes_num', 'regulatory_impact', \n",
    "                    'is_regionally_signigicant', 'act_changes_controlling_activities', 'mineco_solution',\n",
    "                    'problem_addressed', 'act_objectives', 'persons_affected_by_act',\n",
    "                    'relations_regulated_by_act','act_significance']]\n",
    "\n",
    "    id_dict = dict(zip(answers['id'],answers['passed']))\n",
    "    y = np.array([id_dict.get(i, np.nan) for i in df1['id']])\n",
    "    \n",
    "    df1['text'] = [0 if x == 'nothing' else 1 for x in df['text']]   #Does the text for this is exist\n",
    "    df1['text_len'] = [0 if x == 'nothing' else len(x) for x in df['text']]    #Length of the text, 0 if no text\n",
    "    df1.loc[:,['is_regionally_signigicant']] = [1 if i == True else 0 for i in df1['is_regionally_signigicant']]\n",
    "    df1.loc[:,['act_changes_controlling_activities']] = [1 if i == True else 0 \n",
    "                                                         for i in df1['act_changes_controlling_activities']]\n",
    "\n",
    "    #bool features from corresponding columns (empty or not)\n",
    "    df1.loc[:,['problem_addressed', 'act_objectives', 'persons_affected_by_act', 'relations_regulated_by_act',\n",
    "               'act_significance']] = df1.loc[:,['problem_addressed', 'act_objectives', 'persons_affected_by_act',\n",
    "                    'relations_regulated_by_act','act_significance']].applymap(lambda x: 0 if x=='nothing' else 1)\n",
    "    df1['okved_list'] = [0 if x=='nothing' else 1 for x in df1['okved_list']]\n",
    "    df1['year'] = [0 if x=='nothing' else x.year for x in df['publication_date']]    # Number of the year\n",
    "    df1['month'] = [0 if x=='nothing' else x.month for x in df['publication_date']]   # Number of the month\n",
    "    \n",
    "    #months to yeAR_end. 12 max     Linear decline as time limit becomes closer.\n",
    "    df1['year_end'] = [ min(2021*12 + 9 - df1['year'][i]*12 - df1['month'][i], 12) for i in df1.index]\n",
    "\n",
    "    #Dealing with persons (added_by and responsible)\n",
    "    df1['same_person'] = (df['added_by'] == df['responsible'])\n",
    "    responsible = pd.DataFrame(np.unique(df['responsible'], return_counts=True)).transpose()\n",
    "    responsible = dict(zip(responsible[0], responsible[1]))\n",
    "    responsible['nothing'] = 0\n",
    "    added_by = pd.DataFrame(np.unique(df['added_by'], return_counts=True)).transpose()\n",
    "    added_by = dict(zip(added_by[0], added_by[1]))\n",
    "    added_by['nothing'] = 0\n",
    "    df1['responsible_count'] = [responsible[x] for x in df['responsible']]\n",
    "    df1['added_by_count'] = [added_by[x] for x in df['added_by']]\n",
    "    df1['co_developer_bool'] = [0 if x.lstrip().lower() in ['nothing', 'нет', 'отсутствуют', '-', 'соисполнителейнет', \n",
    "                                                         'соисполнителей-нет','соисполнителиотсутствуют'] else \n",
    "                            1 for x in df['co_developer']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def npa_type(s):\n",
    "        '''\n",
    "            Extracting the type of NPA from the text\n",
    "        '''\n",
    "        lines = s.replace('|', '').split('\\n')\n",
    "        todrop =[]\n",
    "        for i in range(len(lines)):\n",
    "            if lines[i].lstrip()=='':\n",
    "                todrop.append(i)\n",
    "        lines = np.array(lines)\n",
    "        lines = np.delete(lines, todrop)\n",
    "        lines = [re.sub(' +', ' ', x).strip(string.punctuation).lstrip().lower().replace(' ', '') for x in lines]\n",
    "        for i in ['приказ', 'федеральныйзакон', 'постановление', 'указ']:\n",
    "            if i in set(lines[:min(len(lines), 10)]):\n",
    "                return i\n",
    "        return 'nothing'\n",
    "\n",
    "    df1['npa_type'] = [npa_type(x) for x in df['text']]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def first_word(table, word):\n",
    "        '''\n",
    "            adding feature that is the 1st word in act_title (1 if it's equal to word, 0 - else)\n",
    "            This function was created before npa_type(s) and was used for top 10 frequently used words. But 'проект'\n",
    "            proved its' significance even after npa_type appearance.\n",
    "        '''\n",
    "        table[word] = [1 if x.split()[0].strip(string.punctuation).strip('«').lower() == word else 0 \n",
    "                       for x in table['act_title']]  \n",
    "\n",
    "    # top_first_words = 10\n",
    "\n",
    "    # A = pd.DataFrame(df['act_title'])\n",
    "    # A[0] = [x.split()[0].strip(string.punctuation).strip('«').lower() for x in A['act_title']]\n",
    "    # for word in pd.DataFrame(np.unique(A[0], return_counts=True)\n",
    "    #                          ).transpose().sort_values(1, ascending=False)[0][:top_first_words].values:\n",
    "    #     first_word(df1, word)\n",
    "    first_word(df1, 'проект')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    del df1['responsible_count']\n",
    "    del df1['added_by_count']\n",
    "    del df1['same_person']\n",
    "    \n",
    "    del df1['act_title']\n",
    "    del df1['publication_date']\n",
    "    \n",
    "    df1 = co_dev_columns(df1, y)\n",
    "    df1_cat_dev = df1.copy()\n",
    "    df1_cat_dev['added_by'] = df['added_by']\n",
    "    df1_cat_dev['responsible'] = df['responsible']\n",
    "\n",
    "    \n",
    "    return df1_cat_dev, id_dict, y\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df1_cat_dev, id_dict, y = data_proc(df, answers)\n",
    "\n",
    "len(df1_cat_dev.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    learning\n",
    "    \n",
    "    Initially both xgBoost and catboost were used. But xgBoost was deleted from final version due to the worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of X_train is: 77314\n",
      "Len of X_test is: 3692\n",
      "Train F1: 0.7636327971753628\n",
      "Train roc_auc_score: 0.9716835528539544\n",
      "Test F1: 0.8416666666666667\n",
      "Test roc_auc_score: 0.9897952497441402\n"
     ]
    }
   ],
   "source": [
    "def learn(df1, answers, method='cat', seed=111111, iterations=1500, learning_rate=0.1,\n",
    "          depth=None, cat_num_features=['year', \"year_end\", 'month']):\n",
    "    '''\n",
    "        Constructing the model\n",
    "        Fitting the answers\n",
    "        Returning AUC and F1 scores\n",
    "    '''\n",
    "\n",
    "    \n",
    "    X = df1[df1['id'].isin(answers['id'])]\n",
    "    \n",
    "    id_dict = dict(zip(answers['id'],answers['passed']))\n",
    "    y = np.array([id_dict[i] for i in X['id']])\n",
    "    \n",
    "    #Only npa with text were used for testing\n",
    "    random.seed(seed)\n",
    "    X_text = X[X['text']==1]\n",
    "    X_test = X.loc[random.sample(list(X_text.index), len(X_text)//2), :]\n",
    "    \n",
    "    \n",
    "    y_test = np.array([id_dict[i] for i in X_test['id']])\n",
    "    X_train = X[~X['id'].isin(X_test['id'])].copy()\n",
    "    y_train = np.array([id_dict[i] for i in X_train['id']])\n",
    "    \n",
    "    \n",
    "    print(f'Len of X_train is: {len(X_train)}')\n",
    "    print(f'Len of X_test is: {len(X_test)}')\n",
    "    \n",
    "    del X_test['id']\n",
    "    del X_train['id']  \n",
    "    del X['id']\n",
    "    \n",
    "    categorical_features = [x for x in X_train.columns if X_train[x].dtype == 'object'] + cat_num_features\n",
    "    \n",
    "    if method=='cat':\n",
    "\n",
    "        xg_cl = CatBoostClassifier(iterations=iterations,random_state=seed, eval_metric='AUC',\n",
    "                                   cat_features=categorical_features, verbose=False, \n",
    "                                   learning_rate=learning_rate, depth=depth)\n",
    "        #xg_cl.fit(X_train, y_train)   #Used for testing\n",
    "        xg_cl.fit(X, y)   #Used for submit\n",
    "\n",
    "\n",
    "\n",
    "    #Printig the results on train\n",
    "    predict = xg_cl.predict(X_train)\n",
    "    predict_proba = xg_cl.predict_proba(X_train)\n",
    "\n",
    "    print(f'Train F1: {sklearn.metrics.f1_score(y_train, predict)}')\n",
    "    print(f'Train roc_auc_score: {sklearn.metrics.roc_auc_score(y_train, pd.DataFrame(predict_proba)[1])}')\n",
    "\n",
    "    #Printig the results on test\n",
    "    predict = xg_cl.predict(X_test)\n",
    "    predict_proba = xg_cl.predict_proba(X_test)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, pd.DataFrame(predict_proba)[1])\n",
    "\n",
    "    print(f'Test F1: {sklearn.metrics.f1_score(y_test, predict)}')\n",
    "    print(f'Test roc_auc_score: {sklearn.metrics.roc_auc_score(y_test, pd.DataFrame(predict_proba)[1])}')\n",
    "    \n",
    "    #Submitting results to result.csv\n",
    "    X_res = df1[~df1['id'].isin(answers['id'])]\n",
    "    Result = pd.DataFrame(X_res['id'].copy()).reset_index(drop=True)\n",
    "    del X_res['id']\n",
    "    predict_proba = xg_cl.predict_proba(X_res)\n",
    "    Result['passed'] = pd.DataFrame(predict_proba)[1]\n",
    "    Result.to_csv(\"result.csv\", index=False)\n",
    "    \n",
    "    return xg_cl, X, y, X_res, X_test, y_test, categorical_features, auc\n",
    "\n",
    "xg_cl, X, y, X_res, X_test, y_test, categorical_features, auc = learn(df1_cat_dev, answers, method='cat', seed=6005,\n",
    "                                                                     iterations=900, learning_rate=0.09, depth=None,\n",
    "                                                                     cat_num_features=['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
